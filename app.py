# -*- coding: utf-8 -*-

import logging
import datetime
import os
import json
import re

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, CallbackQueryHandler

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
TELEGRAM_TOKEN = "7986947716:AAF3L0zIrXfsNWOvsXqMH3liEYBx8asrqs8"

# --- Ø£Ø³Ù…Ø§Ø¡ Ù…Ù„ÙØ§Øª Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
STATIONS_DATA_FILE = "stations_data.json"
PROCEDURES_FILE = "procedures.json"
GENERAL_EVENTS_FILE = "general_events.json"
REMAKES_FILE = "remakes.json" # Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ---
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logging.getLogger("httpx").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

# --- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© ---
def load_data(file_path):
    if not os.path.exists(file_path): return {}
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
            return json.loads(content) if content else {}
    except (json.JSONDecodeError, FileNotFoundError):
        return {}

def save_data(data, file_path):
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def find_station_key(text, stations_data):
    # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø­Ø« Ù„ÙŠØ´Ù…Ù„ Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆØ§Ù„Ø§Ø®ØªØµØ§Ø±
    text_upper = text.upper()
    for key, station_info in stations_data.items():
        if key.upper() == text_upper or station_info.get("short_name", "").upper() == text_upper:
            return key
    return None

# --- Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ Ø§Ù„Ù…Ø¯Ù…Ø¬ (ÙŠØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡Ùˆ) ---
def local_manus_analysis(search_query, stations_data, procedures, general_events):
    # 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¥Ø¬Ø±Ø§Ø¡ Ù‚ÙŠØ§Ø³ÙŠ
    for proc_key, proc_details in procedures.items():
        search_area = proc_details.get('title', '') + ' ' + ' '.join(proc_details.get('keywords', []))
        if any(word.lower() in search_area.lower() for word in search_query.split()):
            response = f"Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø±Ø³Ù…ÙŠØ©ØŒ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ù„Ù‡Ø§ Ø¥Ø¬Ø±Ø§Ø¡ Ø¥ØµÙ„Ø§Ø­ Ù‚ÙŠØ§Ø³ÙŠ.\n\n"
            response += f"<b>ğŸ“œ {proc_details.get('title', 'Ø¨Ù„Ø§ Ø¹Ù†ÙˆØ§Ù†')}</b>\n\n"
            for step_data in proc_details.get('steps', []):
                step_title = step_data.get('title', 'Ø®Ø·ÙˆØ©')
                step_details = step_data.get('details', 'Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙØ§ØµÙŠÙ„.')
                response += f"<b>- {step_title}:</b> {step_details}\n"
            return response

    # 2. Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø£Ø¹Ø·Ø§Ù„
    response = "Ù„Ù… Ø£Ø¬Ø¯ Ø¥Ø¬Ø±Ø§Ø¡Ù‹ Ù‚ÙŠØ§Ø³ÙŠØ§Ù‹ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©ØŒ ÙˆÙ„ÙƒÙ† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø¨Ø±Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©ØŒ Ø¥Ù„ÙŠÙƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„:\n\n"
    found_info = False
    search_words = set(search_query.lower().split())
    
    for station_name, station_info in stations_data.items():
        station_aliases = {station_name.lower(), station_info.get("short_name", "").lower()}
        if search_words.intersection(station_aliases):
            history = station_info.get("history", [])
            if history:
                found_info = True
                response += f"<b>ÙÙŠ Ù…Ø­Ø·Ø© {station_name}:</b>\n"
                for record in reversed(history[-2:]):
                    response += f"- Ø¨ØªØ§Ø±ÙŠØ® {record['date']}ØŒ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… '{record['user']}' Ø§Ù„Ø¢ØªÙŠ: '{record['message']}'\n"
                response += "\n"

    events = general_events.get("events", [])
    for event in events:
        if any(word.lower() in event.get('message', '').lower() for word in search_query.split()):
            found_info = True
            response += f"<b>Ø­Ø¯Ø« Ø¹Ø§Ù… Ù…Ø³Ø¬Ù„ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø°Ø§ ØµÙ„Ø©:</b>\n"
            response += f"- Ø¨ØªØ§Ø±ÙŠØ® {event['date']}ØŒ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… '{event['user']}' Ø§Ù„Ø¢ØªÙŠ: '{event['message']}'\n\n"

    if not found_info:
        response = "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª ØµÙ„Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø­ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹."
    return response

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© ---

async def remake(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """ÙŠØ³Ø¬Ù„ Ø¹Ø·Ù„Ø§Ù‹ Ø¬Ø¯ÙŠØ¯Ø§Ù‹ Ù…Ø¹Ù„Ù‚Ø§Ù‹ (remake)."""
    args = context.args
    if len(args) < 2:
        await update.message.reply_text("Ø®Ø·Ø£.\nÙ…Ø«Ø§Ù„: /remake ATA Ù…Ø´ÙƒÙ„Ø© Ù…Ø³ØªÙ…Ø±Ø© ÙÙŠ Ø¬Ù‡Ø§Ø² SMO")
        return

    station_identifier = args[0]
    description = " ".join(args[1:])
    user_name = update.message.from_user.first_name
    
    stations_data = load_data(STATIONS_DATA_FILE)
    station_key = find_station_key(station_identifier, stations_data)
    
    if not station_key:
        await update.message.reply_text(f"Ø®Ø·Ø£: Ø§Ù„Ù…Ø­Ø·Ø© '{station_identifier}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©.")
        return

    remakes_data = load_data(REMAKES_FILE)
    remakes_list = remakes_data.get("remakes", [])
    
    new_remake = {
        "id": len(remakes_list) + 1,
        "station": station_key,
        "description": description,
        "status": "open",
        "reported_by": user_name,
        "date": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    remakes_list.append(new_remake)
    remakes_data["remakes"] = remakes_list
    save_data(remakes_data, REMAKES_FILE)
    
    await update.message.reply_text(f"âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¹Ø·Ù„ Ù…Ø¹Ù„Ù‚ Ø¬Ø¯ÙŠØ¯ Ø¨Ø±Ù‚Ù… #{new_remake['id']} Ù„Ù…Ø­Ø·Ø© '{station_key}'.")

async def solve(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """ÙŠØ­Ù„ Ø¹Ø·Ù„Ø§Ù‹ Ù…Ø¹Ù„Ù‚Ø§Ù‹ ÙˆÙŠØ­Ø°ÙÙ‡ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©."""
    if not context.args or not context.args[0].isdigit():
        await update.message.reply_text("Ø®Ø·Ø£. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… Ø§Ù„Ø¹Ø·Ù„ Ø§Ù„Ù…Ø±Ø§Ø¯ Ø­Ù„Ù‡.\nÙ…Ø«Ø§Ù„: /solve 12")
        return
        
    remake_id_to_solve = int(context.args[0])
    remakes_data = load_data(REMAKES_FILE)
    remakes_list = remakes_data.get("remakes", [])
    
    remake_found = False
    for remake in remakes_list:
        if remake["id"] == remake_id_to_solve:
            remake["status"] = "solved"
            remake_found = True
            break
            
    if remake_found:
        # ÙÙ„ØªØ±Ø© Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ù„Ø¥Ø¨Ù‚Ø§Ø¡ Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ù…ÙØªÙˆØ­Ø© ÙÙ‚Ø·
        remakes_data["remakes"] = [r for r in remakes_list if r.get('status') == 'open']
        # Ø¥Ø¹Ø§Ø¯Ø© ØªØ±Ù‚ÙŠÙ… Ø§Ù„Ù€ IDs Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ ÙØ¬ÙˆØ§Øª
        for i, r in enumerate(remakes_data["remakes"]):
            r['id'] = i + 1
        save_data(remakes_data, REMAKES_FILE)
        await update.message.reply_text(f"âœ… ØªÙ… Ø­Ù„ Ø§Ù„Ø¹Ø·Ù„ Ø§Ù„Ù…Ø¹Ù„Ù‚ Ø±Ù‚Ù… #{remake_id_to_solve} ÙˆØ¥Ø²Ø§Ù„ØªÙ‡ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©.")
    else:
        await update.message.reply_text(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ø·Ù„ Ù…Ø¹Ù„Ù‚ Ø¨Ø§Ù„Ø±Ù‚Ù… #{remake_id_to_solve}.")

async def remarks(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """ÙŠØ¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© (Ø§Ù„ÙƒÙ„ Ø£Ùˆ Ù„Ù…Ø­Ø·Ø© Ù…Ø¹ÙŠÙ†Ø©)."""
    remakes_data = load_data(REMAKES_FILE)
    remakes_list = [r for r in remakes_data.get("remakes", []) if r.get('status') == 'open']
    
    filter_station = " ".join(context.args) if context.args else None
    
    if filter_station:
        stations_data = load_data(STATIONS_DATA_FILE)
        station_key = find_station_key(filter_station, stations_data)
        if station_key:
            remakes_list = [r for r in remakes_list if r.get("station") == station_key]
            message = f"<b>ğŸ“‹ Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© (Remarks) Ù„Ù…Ø­Ø·Ø© {station_key}:</b>\n\n"
        else:
            await update.message.reply_text(f"Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø­Ø·Ø© Ø¨Ø§Ù„Ø§Ø®ØªØµØ§Ø± '{filter_station}'.")
            return
    else:
        message = "<b>ğŸ“‹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© (Remarks) ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…:</b>\n\n"

    if not remakes_list:
        message += "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ø·Ø§Ù„ Ù…Ø¹Ù„Ù‚Ø© Ø­Ø§Ù„ÙŠØ§Ù‹."
        await update.message.reply_html(message)
        return

    for remake in remakes_list:
        message += (f"<b>- Ø±Ù‚Ù… #{remake['id']} | Ù…Ø­Ø·Ø©: {remake['station']}</b>\n"
                    f"  <b>Ø§Ù„ÙˆØµÙ:</b> {remake['description']}\n"
                    f"  <small><i>Ù…Ø³Ø¬Ù„ Ø¨ÙˆØ§Ø³Ø·Ø©: {remake['reported_by']} ÙÙŠ {remake['date']}</i></small>\n\n")
    
    await update.message.reply_html(message)

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ) ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    await update.message.reply_html(
        f"Ù…Ø±Ø­Ø¨Ø§Ù‹ {user.mention_html()}! Ø£Ù†Ø§ <b>Zekoo v10.0</b>ØŒ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ.\n\n"
        f"<b>ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©:</b>\n"
        f"<code>/remake</code> - Ù„ØªØ³Ø¬ÙŠÙ„ Ø¹Ø·Ù„ Ù…Ø¹Ù„Ù‚.\n"
        f"<code>/remarks</code> - Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©.\n"
        f"<code>/solve</code> - Ù„Ø­Ù„ Ø¹Ø·Ù„ Ù…Ø¹Ù„Ù‚."
    )

async def log_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_message = " ".join(context.args)
    user_name = update.message.from_user.first_name
    if not user_message:
        await update.message.reply_text("Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø¨Ø¹Ø¯ Ø£Ù…Ø± /log.")
        return
    await update.message.reply_text("ÙÙ‡Ù…Øª. Ù„Ø­Ø¸Ø§Øª Ù…Ù† ÙØ¶Ù„ÙƒØŒ Ø£Ù‚ÙˆÙ… Ø¨ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©...")
    stations_data = load_data(STATIONS_DATA_FILE)
    station_key = find_station_key(" ".join(user_message.split()[:2]), stations_data)
    record = {"date": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "user": user_name, "message": user_message}
    if station_key:
        stations_data.setdefault(station_key, {}).setdefault("history", []).append(record)
        save_data(stations_data, STATIONS_DATA_FILE)
        await update.message.reply_text(f"ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ø³Ø¬Ù„ Ù…Ø­Ø·Ø© '{station_key}'.")
    else:
        general_events = load_data(GENERAL_EVENTS_FILE)
        general_events.setdefault("events", []).append(record)
        save_data(general_events, GENERAL_EVENTS_FILE)
        await update.message.reply_text("ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ÙƒÙ€ 'Ø­Ø¯Ø« Ø¹Ø§Ù…'.")

async def search(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_name = update.message.from_user.first_name
    search_query = " ".join(context.args)
    if not search_query:
        await update.message.reply_text("Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙƒØªØ§Ø¨Ø© ÙˆØµÙ Ù„Ù„Ù…Ø´ÙƒÙ„Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø£Ù…Ø± /search.")
        return
    await update.message.reply_text(f"Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙŠØ§ {user_name}. Ù„Ø­Ø¸Ø§Øª Ù…Ù† ÙØ¶Ù„ÙƒØŒ Ø£Ù‚ÙˆÙ… Ø¨Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙˆØ±ÙŠ...")
    stations_data = load_data(STATIONS_DATA_FILE)
    procedures = load_data(PROCEDURES_FILE)
    general_events = load_data(GENERAL_EVENTS_FILE)
    analysis_result = local_manus_analysis(search_query, stations_data, procedures, general_events)
    await update.message.reply_html(analysis_result)

async def add(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    args = context.args
    if len(args) < 3:
        await update.message.reply_text("Ø®Ø·Ø£.\nÙ…Ø«Ø§Ù„: /add Attaba SMO ip=10.1.29.20")
        return
    station_name, device_name, *device_details = args
    stations_data = load_data(STATIONS_DATA_FILE)
    target_station_key = find_station_key(station_name, stations_data)
    if not target_station_key:
        stations_data[station_name] = {"short_name": station_name.upper(), "devices": {}, "history": []}
        target_station_key = station_name
    devices = stations_data[target_station_key].setdefault("devices", {})
    device = devices.setdefault(device_name.upper(), {})
    for detail in device_details:
        if '=' in detail:
            key, value = detail.split('=', 1)
            device[key.lower()] = value
    save_data(stations_data, STATIONS_DATA_FILE)
    await update.message.reply_text(f"ØªÙ… Ø¥Ø¶Ø§ÙØ©/ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ù‡Ø§Ø² '{device_name.upper()}' ÙÙŠ Ù…Ø­Ø·Ø© '{target_station_key}'.")

async def list_stations(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    stations_data = load_data(STATIONS_DATA_FILE)
    if not stations_data:
        await update.message.reply_text("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£ÙŠ Ù…Ø­Ø·Ø§Øª Ù…Ø³Ø¬Ù„Ø©.")
        return
    message = "<b>Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ø·Ø§Øª Ø§Ù„Ù…Ø³Ø¬Ù„Ø©:</b>\n\n"
    for name, data in sorted(stations_data.items()):
        short_name = data.get('short_name', 'N/A')
        devices_count = len(data.get('devices', {}))
        history_count = len(data.get('history', []))
        message += f"â€¢ <b>{name} ({short_name})</b> | Ø£Ø¬Ù‡Ø²Ø©: {devices_count} | Ø³Ø¬Ù„: {history_count}\n"
    await update.message.reply_html(message)

async def hashtag_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    message_text = update.message.text
    hashtag = message_text.lstrip('#').upper()
    stations_data = load_data(STATIONS_DATA_FILE)
    target_station_key = None
    station_info = None
    for key, info in stations_data.items():
        if info.get("short_name", "").upper() == hashtag:
            target_station_key = key
            station_info = info
            break
    if not target_station_key:
        await update.message.reply_text(f"Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø­Ø·Ø© Ø¨Ø§Ù„Ø§Ø®ØªØµØ§Ø± '{hashtag}'.")
        return
    full_name, short_name = target_station_key, station_info.get("short_name", "N/A")
    devices, history = station_info.get("devices", {}), station_info.get("history", [])
    reply = f"<b>ğŸ“ Ø¨Ø·Ø§Ù‚Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø­Ø·Ø©: {full_name} ({short_name})</b>\n-----------------------------------\n"
    if devices:
        reply += "<b>ğŸ’» Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…Ø³Ø¬Ù„Ø©:</b>\n"
        for device_name, details in devices.items():
            reply += f"  â€¢ <b>{device_name}</b>\n"
            if details:
                for key, value in details.items():
                    reply += f"    - {key.capitalize()}: <code>{value}</code>\n"
            else:
                reply += "    - Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙØ§ØµÙŠÙ„ Ù…Ø³Ø¬Ù„Ø©.\n"
    else:
        reply += "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¬Ù‡Ø²Ø© Ù…Ø³Ø¬Ù„Ø© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø­Ø·Ø©.\n"
    reply += "-----------------------------------\n"
    if history:
        reply += "<b>ğŸ“œ Ø¢Ø®Ø± 5 Ø£Ø¹Ø·Ø§Ù„ Ù…Ø³Ø¬Ù„Ø©:</b>\n"
        for record in reversed(history[-5:]):
            reply += f"  - <b>{record['date']}</b> ({record['user']}): {record['message']}\n"
    else:
        reply += "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³Ø¬Ù„ Ø£Ø¹Ø·Ø§Ù„ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø­Ø·Ø©.\n"
    await update.message.reply_html(reply, disable_web_page_preview=True)

def main() -> None:
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª."""
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    application.add_handler(CommandHandler("remake", remake))
    application.add_handler(CommandHandler("solve", solve))
    application.add_handler(CommandHandler("remarks", remarks))

    # Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("log", log_message))
    application.add_handler(CommandHandler("add", add))
    application.add_handler(CommandHandler("list_stations", list_stations))
    application.add_handler(CommandHandler("search", search))
    application.add_handler(MessageHandler(filters.Regex(r'^#\w+'), hashtag_handler))
    
    print("Zekoo v10.0 (Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©) Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
